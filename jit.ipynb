{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0fb2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch device: cuda\n",
      "CUDA available: True\n",
      "Catalyst available: True\n"
     ]
    }
   ],
   "source": [
    "# !pip install pennylane-catalyst torch torchvision\n",
    "\n",
    "# Additional imports for hybrid approach\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from typing import List, Optional, Sequence, Tuple\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Try importing Catalyst\n",
    "try:\n",
    "    from catalyst import qjit\n",
    "    print(\"Catalyst available: True\")\n",
    "    CATALYST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Catalyst available: False (JIT features will be disabled)\")\n",
    "    CATALYST_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d71c921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural readout classes defined successfully\n"
     ]
    }
   ],
   "source": [
    "class ImprovedNeuralReadout(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced feedforward neural network for quantum readout.\n",
    "    Improvements: BatchNorm, LeakyReLU, better regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_layers=[256, 128, 64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "\n",
    "        for i, hidden_size in enumerate(hidden_layers):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(-1)\n",
    "\n",
    "\n",
    "class AttentionReadout(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-based readout that learns reservoir importance.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, n_reservoirs=3, hidden_size=128, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.n_reservoirs = n_reservoirs\n",
    "        self.obs_per_reservoir = input_size // n_reservoirs\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=self.obs_per_reservoir,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "\n",
    "        # Prediction network\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Reshape to (batch, n_reservoirs, obs_per_reservoir)\n",
    "        x_reshaped = x.view(batch_size, self.n_reservoirs, -1)\n",
    "\n",
    "        # Apply attention across reservoirs\n",
    "        attn_output, attn_weights = self.attention(x_reshaped, x_reshaped, x_reshaped)\n",
    "\n",
    "        # Flatten and predict\n",
    "        return self.predictor(attn_output.flatten(1)).squeeze(-1)\n",
    "\n",
    "\n",
    "print(\"Neural readout classes defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85028c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUTrainer class defined successfully\n"
     ]
    }
   ],
   "source": [
    "class GPUTrainer:\n",
    "    \"\"\"\n",
    "    GPU-accelerated trainer with early stopping, learning rate scheduling.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, device='cuda', lr=0.001, weight_decay=1e-4):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "\n",
    "        # AdamW optimizer (better than Adam)\n",
    "        self.optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_model_state = None\n",
    "        self.training_history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    def train_epoch(self, X_train, y_train, batch_size=32):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        # Create data loader\n",
    "        dataset = TensorDataset(\n",
    "            torch.FloatTensor(X_train).to(self.device),\n",
    "            torch.FloatTensor(y_train).to(self.device)\n",
    "        )\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for batch_X, batch_y in loader:\n",
    "            self.optimizer.zero_grad()\n",
    "            predictions = self.model(batch_X)\n",
    "            loss = self.criterion(predictions, batch_y)\n",
    "\n",
    "            loss.backward()\n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        return total_loss / n_batches\n",
    "\n",
    "    def validate(self, X_val, y_val, batch_size=32):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        dataset = TensorDataset(\n",
    "            torch.FloatTensor(X_val).to(self.device),\n",
    "            torch.FloatTensor(y_val).to(self.device)\n",
    "        )\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in loader:\n",
    "                predictions = self.model(batch_X)\n",
    "                loss = self.criterion(predictions, batch_y)\n",
    "                total_loss += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "        return total_loss / n_batches\n",
    "\n",
    "    def train_with_early_stopping(self, X_train, y_train, X_val, y_val,\n",
    "                                  max_epochs=200, patience=20, batch_size=32,\n",
    "                                  verbose=True):\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            train_loss = self.train_epoch(X_train, y_train, batch_size)\n",
    "            val_loss = self.validate(X_val, y_val, batch_size)\n",
    "\n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "\n",
    "            # Update learning rate\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping check\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                self.best_model_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if verbose and (epoch % 10 == 0 or epoch < 5):\n",
    "                print(f\"Epoch {epoch:3d}: Train Loss={train_loss:.6f}, Val Loss={val_loss:.6f}\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        # Load best model\n",
    "        if self.best_model_state is not None:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            self.model.to(self.device)\n",
    "\n",
    "        return self.training_history\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X = torch.FloatTensor(X_test).to(self.device)\n",
    "            predictions = self.model(X).cpu().numpy()\n",
    "        return predictions\n",
    "\n",
    "\n",
    "print(\"GPUTrainer class defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b7e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_bitmasks(num_qubits, offset=0):\n",
    "    masks = []\n",
    "    for q in range(num_qubits):\n",
    "        masks.append(1 << (offset + q))\n",
    "    for i, j in combinations(range(num_qubits), 2):\n",
    "        masks.append((1 << (offset + i)) | (1 << (offset + j)))\n",
    "    return masks\n",
    "\n",
    "def calc_observables(probs, bitmasks):\n",
    "    exps = np.zeros(len(bitmasks), dtype=float)\n",
    "    for basis_index, prob in enumerate(probs):\n",
    "        if prob == 0.0:\n",
    "            continue\n",
    "        for obs_idx, mask in enumerate(bitmasks):\n",
    "            parity = bin(mask & basis_index).count(\"1\") % 2\n",
    "            sign = -1.0 if parity else 1.0\n",
    "            exps[obs_idx] += sign * prob\n",
    "    return exps\n",
    "\n",
    "def apply_amplitude_damping(probs, gamma_vec):\n",
    "    damped = probs.astype(float, copy=True)\n",
    "    if damped.size == 0:\n",
    "        return damped\n",
    "    indices = np.arange(damped.size, dtype=np.int64)\n",
    "    for qubit, gamma in enumerate(gamma_vec):\n",
    "        gamma = float(np.clip(gamma, 0.0, 1.0))\n",
    "        if gamma <= 0.0:\n",
    "            continue\n",
    "        mask = ((indices >> qubit) & 1).astype(bool)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        decay = gamma * damped[mask]\n",
    "        damped[mask] -= decay\n",
    "        targets = indices[mask] & ~(1 << qubit)\n",
    "        np.add.at(damped, targets, decay)\n",
    "    return damped\n",
    "\n",
    "def build_params(f_b, arccos_zs):\n",
    "    params = [f_b]\n",
    "    params.extend(arccos_zs[:-1])\n",
    "    params.extend(list(arccos_zs) * 4)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e56507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_channel_coupling(observables_stack, coupling_pairs, coupling_strength):\n",
    "    if not coupling_pairs or coupling_strength <= 0.0:\n",
    "        return observables_stack\n",
    "    mixed = observables_stack.copy()\n",
    "    for i, j in coupling_pairs:\n",
    "        oi = observables_stack[i]\n",
    "        oj = observables_stack[j]\n",
    "        mixed[i] = (1.0 - coupling_strength) * oi + coupling_strength * oj\n",
    "        mixed[j] = (1.0 - coupling_strength) * oj + coupling_strength * oi\n",
    "    return mixed\n",
    "\n",
    "def qrc_circuit_independent(params, num_qubits):\n",
    "    param_idx = 0\n",
    "    for i in range(num_qubits):\n",
    "        qml.RY(params[param_idx], wires=i)\n",
    "        param_idx += 1\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(i + 1, num_qubits):\n",
    "            qml.CNOT(wires=[i, j])\n",
    "    for i in range(num_qubits):\n",
    "        qml.RY(params[param_idx], wires=i)\n",
    "        param_idx += 1\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(i + 1, num_qubits):\n",
    "            qml.CNOT(wires=[i, j])\n",
    "    for i in range(num_qubits):\n",
    "        qml.RY(params[param_idx], wires=i)\n",
    "        param_idx += 1\n",
    "    for i in range(num_qubits):\n",
    "        qml.RY(params[param_idx], wires=i)\n",
    "        param_idx += 1\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(i + 1, num_qubits):\n",
    "            qml.CNOT(wires=[i, j])\n",
    "    for i in range(num_qubits):\n",
    "        qml.RY(params[param_idx], wires=i)\n",
    "        param_idx += 1\n",
    "    return qml.probs(wires=range(num_qubits))\n",
    "\n",
    "def qrc_circuit_entangled(params, coupling_angle, num_qubits, n_reservoirs, entangled_pair_indices):\n",
    "    param_idx = 0\n",
    "    total_qubits = num_qubits * n_reservoirs\n",
    "    for res in range(n_reservoirs):\n",
    "        offset = res * num_qubits\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(params[param_idx], wires=offset + i)\n",
    "            param_idx += 1\n",
    "        for i in range(num_qubits):\n",
    "            for j in range(i + 1, num_qubits):\n",
    "                qml.CNOT(wires=[offset + i, offset + j])\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(params[param_idx], wires=offset + i)\n",
    "            param_idx += 1\n",
    "        for i in range(num_qubits):\n",
    "            for j in range(i + 1, num_qubits):\n",
    "                qml.CNOT(wires=[offset + i, offset + j])\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(params[param_idx], wires=offset + i)\n",
    "            param_idx += 1\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(params[param_idx], wires=offset + i)\n",
    "            param_idx += 1\n",
    "        for i in range(num_qubits):\n",
    "            for j in range(i + 1, num_qubits):\n",
    "                qml.CNOT(wires=[offset + i, offset + j])\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(params[param_idx], wires=offset + i)\n",
    "            param_idx += 1\n",
    "    \n",
    "    if len(entangled_pair_indices) > 0:\n",
    "        pair_count = len(entangled_pair_indices) // 2\n",
    "        for p in range(pair_count):\n",
    "            ctrl_idx = entangled_pair_indices[2 * p]\n",
    "            tgt_idx = entangled_pair_indices[2 * p + 1]\n",
    "            qml.CNOT(wires=[ctrl_idx, tgt_idx])\n",
    "            qml.RY(coupling_angle, wires=tgt_idx)\n",
    "            qml.CNOT(wires=[ctrl_idx, tgt_idx])\n",
    "    \n",
    "    return qml.probs(wires=range(total_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37cca79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumReservoirPennyLane:\n",
    "    def __init__(self, num_qubits=6, n_reservoirs=3, f_bs=None, b=-0.33,\n",
    "                 ridge_alpha=3e-4, warmup_steps=5, amplitude_damping=None,\n",
    "                 coupling_mode=\"independent\", coupling_strength=0.0,\n",
    "                 coupling_pairs=None):\n",
    "        \n",
    "        self.num_qubits = num_qubits\n",
    "        self.n_reservoirs = n_reservoirs\n",
    "        \n",
    "        if f_bs is None:\n",
    "            default_fb = [0.11, 0.1375, 0.12375]\n",
    "            self.f_bs = default_fb[:self.n_reservoirs]\n",
    "        else:\n",
    "            self.f_bs = list(f_bs)\n",
    "        \n",
    "        if len(self.f_bs) != self.n_reservoirs:\n",
    "            raise ValueError(\"Length of f_bs must match n_reservoirs.\")\n",
    "        \n",
    "        self.b = b\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_qubits = self.num_qubits * self.n_reservoirs\n",
    "        \n",
    "        self._bitmasks_local = _build_bitmasks(self.num_qubits, offset=0)\n",
    "        self.n_observables = len(self._bitmasks_local)\n",
    "        self._bitmasks_entangled = [\n",
    "            _build_bitmasks(self.num_qubits, offset=res * self.num_qubits)\n",
    "            for res in range(self.n_reservoirs)\n",
    "        ]\n",
    "        \n",
    "        self.last_outputs = [np.zeros(self.num_qubits) for _ in range(self.n_reservoirs)]\n",
    "        self.init_qrc_states = deepcopy(self.last_outputs)\n",
    "        self.amplitude_damping = amplitude_damping\n",
    "        self._gamma_map = self._prepare_damping(amplitude_damping)\n",
    "        \n",
    "        # Coupling config\n",
    "        valid = {\"independent\", \"channel\", \"entangled\"}\n",
    "        if coupling_mode not in valid:\n",
    "            raise ValueError(f\"coupling_mode must be in {valid}\")\n",
    "        self.coupling_mode = coupling_mode\n",
    "        self.coupling_strength = float(np.clip(coupling_strength, 0.0, 1.0))\n",
    "        \n",
    "        if self.n_reservoirs < 2:\n",
    "            self._coupling_pairs = []\n",
    "        else:\n",
    "            if coupling_pairs is None:\n",
    "                self._coupling_pairs = [(i, i + 1) for i in range(self.n_reservoirs - 1)]\n",
    "            else:\n",
    "                self._coupling_pairs = coupling_pairs\n",
    "        \n",
    "        self._entangled_pair_indices = []\n",
    "        if self._coupling_pairs:\n",
    "            for src, dst in self._coupling_pairs:\n",
    "                ctrl = src * self.num_qubits + (self.num_qubits - 1)\n",
    "                tgt = dst * self.num_qubits\n",
    "                self._entangled_pair_indices.extend([ctrl, tgt])\n",
    "        \n",
    "        self.ridge = Ridge(alpha=self.ridge_alpha)\n",
    "        self._setup_devices()\n",
    "    \n",
    "    def _setup_devices(self):\n",
    "        try:\n",
    "            self.dev_independent = qml.device('lightning.gpu', wires=self.num_qubits)\n",
    "            self.dev_entangled = qml.device('lightning.gpu', wires=self.total_qubits)\n",
    "            self._device_type = \"lightning.gpu\"\n",
    "        except:\n",
    "            self.dev_independent = qml.device('lightning.qubit', wires=self.num_qubits)\n",
    "            self.dev_entangled = qml.device('lightning.qubit', wires=self.total_qubits)\n",
    "            self._device_type = \"lightning.qubit\"\n",
    "    \n",
    "    def _prepare_damping(self, amplitude_damping: Optional[Sequence[float]]):\n",
    "        if amplitude_damping is None:\n",
    "            return None\n",
    "        if np.isscalar(amplitude_damping):\n",
    "            gamma = float(np.clip(amplitude_damping, 0.0, 1.0))\n",
    "            return [np.full(self.num_qubits, gamma, dtype=float) for _ in range(self.n_reservoirs)]\n",
    "        arr = np.array(amplitude_damping, dtype=float)\n",
    "        if arr.ndim == 1:\n",
    "            if arr.size == 1:\n",
    "                gamma = float(np.clip(arr[0], 0.0, 1.0))\n",
    "                return [np.full(self.num_qubits, gamma, dtype=float) for _ in range(self.n_reservoirs)]\n",
    "            if arr.size == self.n_reservoirs:\n",
    "                return [np.full(self.num_qubits, float(np.clip(g, 0.0, 1.0)), dtype=float) for g in arr]\n",
    "            if arr.size == self.num_qubits:\n",
    "                base = np.clip(arr, 0.0, 1.0).astype(float)\n",
    "                return [base.copy() for _ in range(self.n_reservoirs)]\n",
    "            if arr.size == self.total_qubits:\n",
    "                clipped = np.clip(arr, 0.0, 1.0).astype(float)\n",
    "                return [\n",
    "                    clipped[i * self.num_qubits:(i + 1) * self.num_qubits].copy()\n",
    "                    for i in range(self.n_reservoirs)\n",
    "                ]\n",
    "        if arr.ndim == 2 and arr.shape == (self.n_reservoirs, self.num_qubits):\n",
    "            clipped = np.clip(arr, 0.0, 1.0).astype(float)\n",
    "            return [row.copy() for row in clipped]\n",
    "        raise ValueError(\n",
    "            \"amplitude_damping must be None, a scalar, length-n_reservoirs, \"  \"length-num_qubits, length-total_qubits, or (n_reservoirs, num_qubits).\"\n",
    "        )\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc218fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bound evolve/train/predict methods to QuantumReservoirPennyLane\n"
     ]
    }
   ],
   "source": [
    "# Attach evolve + train/predict methods to QuantumReservoirPennyLane\n",
    "\n",
    "def _evolve_independent(self, input_value):\n",
    "    observables = []\n",
    "    qnode = qml.QNode(lambda p: qrc_circuit_independent(p, self.num_qubits), self.dev_independent)\n",
    "    for res_idx in range(self.n_reservoirs):\n",
    "        zs = np.clip(self.last_outputs[res_idx], -1.0, 1.0)\n",
    "        f_b = input_value * self.b * self.f_bs[res_idx]\n",
    "        arccos_zs = np.arccos(zs) * self.b\n",
    "        params_list = build_params(f_b, arccos_zs)\n",
    "        probs = qnode(params_list)\n",
    "        if self._gamma_map is not None:\n",
    "            probs = apply_amplitude_damping(probs, self._gamma_map[res_idx])\n",
    "        observables.append(calc_observables(probs, self._bitmasks_local))\n",
    "    observables_stack = np.stack(observables)\n",
    "    if self.coupling_mode == \"channel\" and getattr(self, \"_coupling_pairs\", []):\n",
    "        observables_stack = apply_channel_coupling(observables_stack, self._coupling_pairs, self.coupling_strength)\n",
    "    for res_idx in range(self.n_reservoirs):\n",
    "        self.last_outputs[res_idx] = observables_stack[res_idx, :self.num_qubits]\n",
    "    return observables_stack.reshape(-1)\n",
    "\n",
    "\n",
    "def _evolve_entangled(self, input_value):\n",
    "    param_chunks = []\n",
    "    for res_idx in range(self.n_reservoirs):\n",
    "        zs = np.clip(self.last_outputs[res_idx], -1.0, 1.0)\n",
    "        f_b = input_value * self.b * self.f_bs[res_idx]\n",
    "        arccos_zs = np.arccos(zs) * self.b\n",
    "        param_chunks.append(build_params(f_b, arccos_zs))\n",
    "    params_flat = np.concatenate(param_chunks)\n",
    "    coupling_angle = float(self.coupling_strength) * np.pi\n",
    "    qnode = qml.QNode(\n",
    "        lambda p, a: qrc_circuit_entangled(p, a, self.num_qubits, self.n_reservoirs, self._entangled_pair_indices),\n",
    "        self.dev_entangled\n",
    "    )\n",
    "    probs = qnode(params_flat, coupling_angle)\n",
    "    if self._gamma_map is not None:\n",
    "        gamma_flat = np.concatenate(self._gamma_map)\n",
    "        probs = apply_amplitude_damping(probs, gamma_flat)\n",
    "    observables = []\n",
    "    for res_idx, bitmasks in enumerate(self._bitmasks_entangled):\n",
    "        obs = calc_observables(probs, bitmasks)\n",
    "        self.last_outputs[res_idx] = obs[:self.num_qubits]\n",
    "        observables.append(obs)\n",
    "    return np.concatenate(observables)\n",
    "\n",
    "\n",
    "def evolve_qrc(self, input_value):\n",
    "    if self.coupling_mode == \"entangled\":\n",
    "        return self._evolve_entangled(input_value)\n",
    "    return self._evolve_independent(input_value)\n",
    "\n",
    "\n",
    "def reset_reservoirs(self):\n",
    "    self.last_outputs = deepcopy(self.init_qrc_states)\n",
    "\n",
    "\n",
    "def train(self, train_data):\n",
    "    all_states, all_targets = [], []\n",
    "    for series in train_data:\n",
    "        self.reset_reservoirs()\n",
    "        for _ in range(self.warmup_steps):\n",
    "            _ = self.evolve_qrc(series[0])\n",
    "        for t in range(len(series) - 1):\n",
    "            state = self.evolve_qrc(series[t])\n",
    "            if not np.all(np.isfinite(state)):\n",
    "                state = np.nan_to_num(state, nan=0.0)\n",
    "            all_states.append(state)\n",
    "            all_targets.append(series[t + 1])\n",
    "    X = np.array(all_states)\n",
    "    y = np.array(all_targets)\n",
    "    self.ridge.fit(X, y)\n",
    "\n",
    "\n",
    "def predict(self, test_data, n_predict=20):\n",
    "    n_test = test_data.shape[0]\n",
    "    predictions = np.zeros((n_test, n_predict))\n",
    "    for test_idx in range(n_test):\n",
    "        series = test_data[test_idx]\n",
    "        self.reset_reservoirs()\n",
    "        for _ in range(self.warmup_steps):\n",
    "            _ = self.evolve_qrc(series[0])\n",
    "        for t in range(len(series) - 1):\n",
    "            _ = self.evolve_qrc(series[t])\n",
    "        last_value = series[-1]\n",
    "        for step in range(n_predict):\n",
    "            state = self.evolve_qrc(last_value)\n",
    "            if not np.all(np.isfinite(state)):\n",
    "                state = np.nan_to_num(state, nan=0.0)\n",
    "            last_value = self.ridge.predict(state.reshape(1, -1))[0]\n",
    "            predictions[test_idx, step] = last_value\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Bind to class\n",
    "QuantumReservoirPennyLane._evolve_independent = _evolve_independent\n",
    "QuantumReservoirPennyLane._evolve_entangled = _evolve_entangled\n",
    "QuantumReservoirPennyLane.evolve_qrc = evolve_qrc\n",
    "QuantumReservoirPennyLane.reset_reservoirs = reset_reservoirs\n",
    "QuantumReservoirPennyLane.train = train\n",
    "QuantumReservoirPennyLane.predict = predict\n",
    "\n",
    "print(\"Bound evolve/train/predict methods to QuantumReservoirPennyLane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733d0371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantumReservoirJIT class defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Assume QuantumReservoirPennyLane and helper functions (qrc_circuit_entangled, etc.) are defined elsewhere\n",
    "class QuantumReservoirJIT(QuantumReservoirPennyLane):\n",
    "    \"\"\"\n",
    "    Enhanced Quantum Reservoir with Catalyst JIT compilation.\n",
    "    Inherits from QuantumReservoirPennyLane, adds JIT and neural readout support.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, use_jit=True, readout_type='ridge', **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.use_jit = use_jit and CATALYST_AVAILABLE\n",
    "        self.readout_type = readout_type\n",
    "        self.neural_readout = None\n",
    "        self.neural_trainer = None\n",
    "\n",
    "        if self.use_jit:\n",
    "            print(f\"Setting up JIT-compiled circuits...\")\n",
    "            self._setup_jit_circuits()\n",
    "\n",
    "    def _setup_jit_circuits(self):\n",
    "        \"\"\"Create JIT-compiled versions of quantum circuits\"\"\"\n",
    "        if not CATALYST_AVAILABLE:\n",
    "            print(\"Catalyst not available, skipping JIT setup\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            if self.coupling_mode == \"entangled\":\n",
    "                @qjit\n",
    "                @qml.qnode(self.dev_entangled)\n",
    "                def circuit_jit(params, coupling_angle):\n",
    "                    return qrc_circuit_entangled(\n",
    "                        params, coupling_angle, self.num_qubits,\n",
    "                        self.n_reservoirs, self._entangled_pair_indices\n",
    "                    )\n",
    "                self.circuit_jit = circuit_jit\n",
    "                print(\"JIT-compiled entangled circuit created\")\n",
    "            else:\n",
    "                # For independent/channel modes, create per-reservoir JIT circuits\n",
    "                @qjit\n",
    "                @qml.qnode(self.dev_independent)\n",
    "                def circuit_jit(params):\n",
    "                    return qrc_circuit_independent(params, self.num_qubits)\n",
    "                self.circuit_jit = circuit_jit\n",
    "                print(\"JIT-compiled independent circuit created\")\n",
    "        except Exception as e:\n",
    "            print(f\"JIT compilation failed: {e}\")\n",
    "            print(\"Falling back to non-JIT mode\")\n",
    "            self.use_jit = False\n",
    "\n",
    "    def evolve_qrc(self, input_value):\n",
    "        \"\"\"Override with JIT support\"\"\"\n",
    "        if self.use_jit and hasattr(self, 'circuit_jit'):\n",
    "            return self._evolve_jit(input_value)\n",
    "        return super().evolve_qrc(input_value)\n",
    "\n",
    "    def _evolve_jit(self, input_value):\n",
    "        \"\"\"JIT-optimized quantum evolution\"\"\"\n",
    "        if self.coupling_mode == \"entangled\":\n",
    "            return self._evolve_entangled_jit(input_value)\n",
    "        return self._evolve_independent_jit(input_value)\n",
    "\n",
    "    def _evolve_independent_jit(self, input_value):\n",
    "        \"\"\"JIT-compiled independent mode evolution\"\"\"\n",
    "        observables = []\n",
    "\n",
    "        for res_idx in range(self.n_reservoirs):\n",
    "            zs = np.clip(self.last_outputs[res_idx], -1.0, 1.0)\n",
    "            f_b = input_value * self.b * self.f_bs[res_idx]\n",
    "            arccos_zs = np.arccos(zs) * self.b\n",
    "            params_list = build_params(f_b, arccos_zs)\n",
    "\n",
    "            # Use JIT-compiled circuit\n",
    "            probs = np.array(self.circuit_jit(params_list))\n",
    "\n",
    "            if self._gamma_map is not None:\n",
    "                probs = apply_amplitude_damping(probs, self._gamma_map[res_idx])\n",
    "            observables.append(calc_observables(probs, self._bitmasks_local))\n",
    "\n",
    "        observables_stack = np.stack(observables)\n",
    "        if self.coupling_mode == \"channel\":\n",
    "            observables_stack = apply_channel_coupling(\n",
    "                observables_stack, self._coupling_pairs, self.coupling_strength\n",
    "            )\n",
    "\n",
    "        for res_idx in range(self.n_reservoirs):\n",
    "            self.last_outputs[res_idx] = observables_stack[res_idx, :self.num_qubits]\n",
    "\n",
    "        return observables_stack.reshape(-1)\n",
    "\n",
    "    def _evolve_entangled_jit(self, input_value):\n",
    "        \"\"\"JIT-compiled entangled mode evolution\"\"\"\n",
    "        param_chunks = []\n",
    "        for res_idx in range(self.n_reservoirs):\n",
    "            zs = np.clip(self.last_outputs[res_idx], -1.0, 1.0)\n",
    "            f_b = input_value * self.b * self.f_bs[res_idx]\n",
    "            arccos_zs = np.arccos(zs) * self.b\n",
    "            param_chunks.append(build_params(f_b, arccos_zs))\n",
    "\n",
    "        params_flat = np.concatenate(param_chunks)\n",
    "        coupling_angle = float(self.coupling_strength) * np.pi\n",
    "\n",
    "        # Use JIT-compiled circuit\n",
    "        probs = np.array(self.circuit_jit(params_flat, coupling_angle))\n",
    "\n",
    "        if self._gamma_map is not None:\n",
    "            gamma_flat = np.concatenate(self._gamma_map)\n",
    "            probs = apply_amplitude_damping(probs, gamma_flat)\n",
    "\n",
    "        observables = []\n",
    "        for res_idx, bitmasks in enumerate(self._bitmasks_entangled):\n",
    "            obs = calc_observables(probs, bitmasks)\n",
    "            self.last_outputs[res_idx] = obs[:self.num_qubits]\n",
    "            observables.append(obs)\n",
    "\n",
    "        return np.concatenate(observables)\n",
    "\n",
    "    def train_neural_readout(self, train_data, val_split=0.2, neural_config=None,\n",
    "                             training_config=None):\n",
    "        \"\"\"\n",
    "        Train neural network readout instead of Ridge regression.\n",
    "        \"\"\"\n",
    "        if neural_config is None:\n",
    "            neural_config = {\n",
    "                'hidden_layers': [256, 128, 64],\n",
    "                'dropout': 0.3,\n",
    "                'readout_class': ImprovedNeuralReadout\n",
    "            }\n",
    "\n",
    "        if training_config is None:\n",
    "            training_config = {\n",
    "                'max_epochs': 200,\n",
    "                'patience': 20,\n",
    "                'batch_size': 32,\n",
    "                'lr': 0.001,\n",
    "                'weight_decay': 1e-4\n",
    "            }\n",
    "\n",
    "        print(\"Collecting quantum states...\")\n",
    "        all_states, all_targets = [], []\n",
    "\n",
    "        for series_idx in tqdm(range(train_data.shape[0]), desc=\"Quantum Evolution\", leave=False):\n",
    "            series = train_data[series_idx]\n",
    "            self.reset_reservoirs()\n",
    "\n",
    "            # Warmup\n",
    "            for _ in range(self.warmup_steps):\n",
    "                _ = self.evolve_qrc(series[0])\n",
    "\n",
    "            # Collect states\n",
    "            for t in range(len(series) - 1):\n",
    "                state = self.evolve_qrc(series[t])\n",
    "                if not np.all(np.isfinite(state)):\n",
    "                    state = np.nan_to_num(state, nan=0.0)\n",
    "                all_states.append(state)\n",
    "                all_targets.append(series[t + 1])\n",
    "\n",
    "        X = np.array(all_states)\n",
    "        y = np.array(all_targets)\n",
    "\n",
    "        # Train/validation split\n",
    "        n_train = int(len(X) * (1 - val_split))\n",
    "        X_train, X_val = X[:n_train], X[n_train:]\n",
    "        y_train, y_val = y[:n_train], y[n_train:]\n",
    "\n",
    "        print(f\"Training neural readout: {X_train.shape[0]} train, {X_val.shape[0]} val\")\n",
    "\n",
    "        # Create neural network\n",
    "        ReadoutClass = neural_config.pop('readout_class', ImprovedNeuralReadout)\n",
    "        self.neural_readout = ReadoutClass(input_size=X.shape[1], **neural_config)\n",
    "\n",
    "        # Train on GPU\n",
    "        self.neural_trainer = GPUTrainer(self.neural_readout, device=device,\n",
    "                                         lr=training_config['lr'],\n",
    "                                         weight_decay=training_config['weight_decay'])\n",
    "\n",
    "        history = self.neural_trainer.train_with_early_stopping(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            max_epochs=training_config['max_epochs'],\n",
    "            patience=training_config['patience'],\n",
    "            batch_size=training_config['batch_size'],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        self.readout_type = 'neural'\n",
    "        print(\"Neural readout training complete!\")\n",
    "        return history\n",
    "\n",
    "    def predict(self, test_data, n_predict=20):\n",
    "        \"\"\"Override predict to use neural readout if available\"\"\"\n",
    "        n_test = test_data.shape[0]\n",
    "        predictions = np.zeros((n_test, n_predict))\n",
    "\n",
    "        for test_idx in tqdm(range(n_test), desc=\"Predicting\", leave=False):\n",
    "            series = test_data[test_idx]\n",
    "            self.reset_reservoirs()\n",
    "\n",
    "            # Warmup\n",
    "            for _ in range(self.warmup_steps):\n",
    "                _ = self.evolve_qrc(series[0])\n",
    "\n",
    "            # Initialize\n",
    "            for t in range(len(series) - 1):\n",
    "                _ = self.evolve_qrc(series[t])\n",
    "\n",
    "            last_value = series[-1]\n",
    "\n",
    "            # Predict future\n",
    "            for step in range(n_predict):\n",
    "                state = self.evolve_qrc(last_value)\n",
    "                if not np.all(np.isfinite(state)):\n",
    "                    state = np.nan_to_num(state, nan=0.0)\n",
    "\n",
    "                # Use neural or ridge readout\n",
    "                if self.readout_type == 'neural' and self.neural_readout is not None:\n",
    "                    last_value = self.neural_trainer.predict(state.reshape(1, -1))[0]\n",
    "                else:\n",
    "                    last_value = self.ridge.predict(state.reshape(1, -1))[0]\n",
    "\n",
    "                predictions[test_idx, step] = last_value\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "print(\"QuantumReservoirJIT class defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3c4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_damped_oscillator_data(n_train=10, n_test=4, n_points=26, seed=1):\n",
    "    rng = np.random.Generator(np.random.PCG64(seed))\n",
    "    t = np.linspace(0, 26, num=n_points)\n",
    "    n_total = n_train + n_test\n",
    "    oscis = 0.5 + rng.standard_normal(n_total) * 0.4\n",
    "    data = np.zeros((n_total, n_points))\n",
    "    for j in range(n_total):\n",
    "        omega = oscis[j]\n",
    "        data[j, :] = (\n",
    "            np.exp(-0.05 * t) * \n",
    "            (np.cos(omega * t) + np.cos(omega * t / np.sqrt(2))) * 30 +\n",
    "            rng.standard_normal(n_points) * 0.3\n",
    "        )\n",
    "    return data\n",
    "data = generate_damped_oscillator_data(n_train=10, n_test=4, n_points=26, seed=1)\n",
    "train_data = data[:10]\n",
    "test_data = data[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4992511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. BASELINE: Ridge Regression (No JIT)\n",
      "R²=0.6716, NRMSE=0.5731, Time=1759.05s\n",
      "2. Ridge + JIT Compilation\n",
      "Setting up JIT-compiled circuits...\n",
      "JIT-compiled entangled circuit created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-10-15 08:08:12,294:jax._src.xla_bridge:909: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3640d19c125c407ca9c5d6e810b42aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=0.6716, NRMSE=0.5731, Time=1751.86s, Speedup=1.0x\n",
      "3. Neural Network Readout (No JIT)\n",
      "Collecting quantum states...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a05b1db05cc43f68fa3aa065f86c7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantum Evolution:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural readout: 200 train, 50 val\n",
      "Epoch   0: Train Loss=406.549227, Val Loss=266.264210\n",
      "Epoch   1: Train Loss=408.759818, Val Loss=263.442757\n",
      "Epoch   2: Train Loss=352.694639, Val Loss=257.201138\n",
      "Epoch   3: Train Loss=361.865069, Val Loss=249.217600\n",
      "Epoch   4: Train Loss=332.444744, Val Loss=240.402662\n",
      "Epoch  10: Train Loss=268.635587, Val Loss=155.939148\n",
      "Epoch  20: Train Loss=194.337060, Val Loss=89.469435\n",
      "Epoch  30: Train Loss=109.223185, Val Loss=50.885292\n",
      "Epoch  40: Train Loss=63.192042, Val Loss=26.264825\n",
      "Epoch  50: Train Loss=61.264717, Val Loss=21.837965\n",
      "Epoch  60: Train Loss=50.611004, Val Loss=14.206161\n",
      "Epoch  70: Train Loss=60.510548, Val Loss=10.295516\n",
      "Epoch  80: Train Loss=46.800715, Val Loss=11.522503\n",
      "Epoch  90: Train Loss=44.142929, Val Loss=8.294345\n",
      "Early stopping at epoch 93\n",
      "Neural readout training complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2186160c0b5b45259382f38e96dae8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=-0.1367, NRMSE=1.0662, Time=1747.94s\n",
      "4. HYBRID: JIT + Neural Network Readout\n",
      "Setting up JIT-compiled circuits...\n",
      "JIT-compiled entangled circuit created\n",
      "Collecting quantum states...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb3367965c54aebb8e02e8218dd103b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantum Evolution:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural readout: 200 train, 50 val\n",
      "Epoch   0: Train Loss=438.207280, Val Loss=266.593384\n",
      "Epoch   1: Train Loss=433.036024, Val Loss=264.096060\n",
      "Epoch   2: Train Loss=356.488669, Val Loss=258.296865\n",
      "Epoch   3: Train Loss=350.505057, Val Loss=250.825762\n",
      "Epoch   4: Train Loss=322.246368, Val Loss=242.198568\n",
      "Epoch  10: Train Loss=260.626744, Val Loss=152.121567\n",
      "Epoch  20: Train Loss=164.842790, Val Loss=92.513235\n",
      "Epoch  30: Train Loss=104.123186, Val Loss=50.352417\n",
      "Epoch  40: Train Loss=81.171091, Val Loss=36.640297\n",
      "Epoch  50: Train Loss=78.194746, Val Loss=23.248048\n",
      "Epoch  60: Train Loss=65.821684, Val Loss=27.281194\n",
      "Epoch  70: Train Loss=41.539595, Val Loss=8.825106\n",
      "Epoch  80: Train Loss=54.953954, Val Loss=11.196260\n",
      "Epoch  90: Train Loss=49.614410, Val Loss=8.101940\n",
      "Early stopping at epoch 96\n",
      "Neural readout training complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668f45bd22a64a198909c01bb082f672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=0.2949, NRMSE=0.8397, Time=1759.10s, Speedup=1.0x\n"
     ]
    }
   ],
   "source": [
    "def run_hybrid_experiments(train_data, test_data, base_cfg, init_points=6, n_predict=20):\n",
    "    \"\"\"\n",
    "    Compare Ridge, Neural, and JIT+Neural approaches.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 1. Original Ridge (no JIT)\n",
    "  \n",
    "    print(\"1. BASELINE: Ridge Regression (No JIT)\")\n",
    "\n",
    "    cfg_ridge = dict(base_cfg, coupling_mode=\"entangled\", coupling_strength=0.20)\n",
    "    model_ridge = QuantumReservoirPennyLane(**cfg_ridge)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_ridge.train(train_data)\n",
    "    preds_ridge = model_ridge.predict(test_data[:, :init_points], n_predict=n_predict)\n",
    "    time_ridge = time.time() - start_time\n",
    "\n",
    "    truth = test_data[:, init_points:].flatten()\n",
    "    results['ridge'] = {\n",
    "        'predictions': preds_ridge,\n",
    "        'r2': r2_score(truth, preds_ridge.flatten()),\n",
    "        'mse': mean_squared_error(truth, preds_ridge.flatten()),\n",
    "        'nrmse': np.sqrt(mean_squared_error(truth, preds_ridge.flatten())) / (np.std(truth) + 1e-12),\n",
    "        'time': time_ridge\n",
    "    }\n",
    "    print(f\"R²={results['ridge']['r2']:.4f}, NRMSE={results['ridge']['nrmse']:.4f}, Time={time_ridge:.2f}s\")\n",
    "\n",
    "    # 2. Ridge with JIT\n",
    "    \n",
    "    print(\"2. Ridge + JIT Compilation\")\n",
    "\n",
    "    model_jit = QuantumReservoirJIT(**cfg_ridge, use_jit=True, readout_type='ridge')\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_jit.train(train_data)\n",
    "    preds_jit = model_jit.predict(test_data[:, :init_points], n_predict=n_predict)\n",
    "    time_jit = time.time() - start_time\n",
    "\n",
    "    results['jit'] = {\n",
    "        'predictions': preds_jit,\n",
    "        'r2': r2_score(truth, preds_jit.flatten()),\n",
    "        'mse': mean_squared_error(truth, preds_jit.flatten()),\n",
    "        'nrmse': np.sqrt(mean_squared_error(truth, preds_jit.flatten())) / (np.std(truth) + 1e-12),\n",
    "        'time': time_jit,\n",
    "        'speedup': time_ridge / time_jit if time_jit > 0 else 0\n",
    "    }\n",
    "    print(f\"R²={results['jit']['r2']:.4f}, NRMSE={results['jit']['nrmse']:.4f}, Time={time_jit:.2f}s, Speedup={results['jit']['speedup']:.1f}x\")\n",
    "\n",
    "    # 3. Neural readout (no JIT)\n",
    "   \n",
    "    print(\"3. Neural Network Readout (No JIT)\")\n",
    "\n",
    "    model_neural = QuantumReservoirJIT(**cfg_ridge, use_jit=False, readout_type='neural')\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_neural.train_neural_readout(train_data, val_split=0.2)\n",
    "    preds_neural = model_neural.predict(test_data[:, :init_points], n_predict=n_predict)\n",
    "    time_neural = time.time() - start_time\n",
    "\n",
    "    results['neural'] = {\n",
    "        'predictions': preds_neural,\n",
    "        'r2': r2_score(truth, preds_neural.flatten()),\n",
    "        'mse': mean_squared_error(truth, preds_neural.flatten()),\n",
    "        'nrmse': np.sqrt(mean_squared_error(truth, preds_neural.flatten())) / (np.std(truth) + 1e-12),\n",
    "        'time': time_neural\n",
    "    }\n",
    "    print(f\"R²={results['neural']['r2']:.4f}, NRMSE={results['neural']['nrmse']:.4f}, Time={time_neural:.2f}s\")\n",
    "\n",
    "    # 4. HYBRID: JIT + Neural readout\n",
    "    \n",
    "    print(\"4. HYBRID: JIT + Neural Network Readout\")\n",
    " \n",
    "    model_hybrid = QuantumReservoirJIT(**cfg_ridge, use_jit=True, readout_type='neural')\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_hybrid.train_neural_readout(train_data, val_split=0.2)\n",
    "    preds_hybrid = model_hybrid.predict(test_data[:, :init_points], n_predict=n_predict)\n",
    "    time_hybrid = time.time() - start_time\n",
    "\n",
    "    results['hybrid'] = {\n",
    "        'predictions': preds_hybrid,\n",
    "        'r2': r2_score(truth, preds_hybrid.flatten()),\n",
    "        'mse': mean_squared_error(truth, preds_hybrid.flatten()),\n",
    "        'nrmse': np.sqrt(mean_squared_error(truth, preds_hybrid.flatten())) / (np.std(truth) + 1e-12),\n",
    "        'time': time_hybrid,\n",
    "        'speedup': time_ridge / time_hybrid if time_hybrid > 0 else 0\n",
    "    }\n",
    "    print(f\"R²={results['hybrid']['r2']:.4f}, NRMSE={results['hybrid']['nrmse']:.4f}, Time={time_hybrid:.2f}s, Speedup={results['hybrid']['speedup']:.1f}x\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Define base configuration for the quantum reservoir\n",
    "base_cfg = dict(\n",
    "    num_qubits=6,\n",
    "    n_reservoirs=3,\n",
    "    f_bs=[0.08, 0.10, 0.12],\n",
    "    b=-0.40,\n",
    "    warmup_steps=8,\n",
    "    ridge_alpha=3e-4\n",
    ")\n",
    "\n",
    "# Assume train_data and test_data are pre-loaded numpy arrays\n",
    "# Example placeholder data:\n",
    "# train_data = np.random.rand(50, 20)\n",
    "# test_data = np.random.rand(10, 26)\n",
    "\n",
    "# Run comparison\n",
    "hybrid_results = run_hybrid_experiments(train_data, test_data, base_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd179832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443e4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qrc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
